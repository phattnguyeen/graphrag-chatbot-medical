{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0efc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain==0.1.0 openai==1.7.2 langchain-openai==0.3.8 langchain-community==0.0.12 langchainhub==0.1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eef046",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f868e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"phi\")\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adc518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = Ollama(model=\"phi\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI assistant that tells jokes.\"),\n",
    "    HumanMessage(content=\"Tell me a joke.\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a813a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me historical fact about the {event} in {location}.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd951c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.format(event=\"World War II\", location=\"Europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0919a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be452021",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e188a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "import os\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o HuggingFace Embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 2. K·∫øt n·ªëi Neo4j v√† build vectorstore\n",
    "vectorstore = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding_model,\n",
    "    url=os.getenv(\"NEO4J_URL\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name=\"medical_full_index\",  # 1 index chung\n",
    "    node_label=\"Disease|Symptom|Treatment|Prevention|DiagnoseMethod|Cause\",\n",
    "    text_node_properties=[\"name\", \"overview\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff79a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "import os\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o model embedding\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 2. Th√¥ng tin k·∫øt n·ªëi Neo4j\n",
    "neo4j_config = {\n",
    "    \"url\": os.getenv(\"NEO4J_URL\"),\n",
    "    \"username\": os.getenv(\"NEO4J_USERNAME\"),\n",
    "    \"password\": os.getenv(\"NEO4J_PASSWORD\")  # <-- ch·ªânh l·∫°i n·∫øu c·∫ßn\n",
    "}\n",
    "\n",
    "# 3. C√°c lo·∫°i node c·∫ßn t·∫°o ri√™ng\n",
    "node_types = [\"Disease\", \"Symptom\", \"Treatment\", \"Prevention\", \"DiagnoseMethod\", \"Cause\"]\n",
    "\n",
    "# 4. Duy·ªát t·ª´ng lo·∫°i node v√† t·∫°o vectorstore ri√™ng bi·ªát\n",
    "vectorstores = {}\n",
    "for node_label in node_types:\n",
    "    index_name = f\"index_{node_label.lower()}\"\n",
    "    properties = [\"name\", \"overview\"] if node_label == \"Disease\" else [\"name\"]\n",
    "\n",
    "    print(f\"üëâ ƒêang t·∫°o vectorstore cho {node_label}...\")\n",
    "\n",
    "    vectorstores[node_label] = Neo4jVector.from_existing_graph(\n",
    "        embedding=embedding_model,\n",
    "        index_name=index_name,\n",
    "        node_label=node_label,\n",
    "        text_node_properties=properties,\n",
    "        embedding_node_property=\"embedding\",\n",
    "        **neo4j_config\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o vectorstore cho t·∫•t c·∫£ c√°c node!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "\n",
    "# K·∫øt n·ªëi\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URL\"), \n",
    "    auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "def drop_all_vector_indexes():\n",
    "    with driver.session() as session:\n",
    "        indexes = session.run(\"\"\"\n",
    "        SHOW INDEXES YIELD name, type\n",
    "        WHERE type = \"VECTOR\"\n",
    "        RETURN name\n",
    "        \"\"\")\n",
    "        for record in indexes:\n",
    "            index_name = record[\"name\"]\n",
    "            print(f\"Dropping index {index_name}...\")\n",
    "            session.run(f\"DROP INDEX {index_name} IF EXISTS\")\n",
    "\n",
    "drop_all_vector_indexes()\n",
    "print(\"‚úÖ ƒê√£ drop to√†n b·ªô vector index!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823c10a",
   "metadata": {},
   "source": [
    "### Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012422dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© [DiagnoseMethod] X√©t nghi·ªám hormone sinh d·ª•c. | Score: 0.9072\n",
      "üß© [DiagnoseMethod] ƒê·ªÉ ch·∫©n ƒëo√°n b·ªánh, tr∆∞·ªõc h·∫øt c√≥ th·ªÉ th√¥ng qua k·∫øt qu·∫£ kh√°m l√¢m s√†ng c√°c v·∫øt lo√©t, kh√°m h·∫°ch b·∫πn s∆∞ng v√† lo·∫°i tr·ª´ c√°c b·ªánh l√¢y truy·ªÅn qua ƒë∆∞·ªùng t√¨nh d·ª•c kh√°c. | Score: 0.8994\n",
      "üß© [DiagnoseMethod] D·ª±a v√†o d·∫•u hi·ªáu l√¢m s√†ng c·ªßa b·ªánh: ¬†B·ªánh nh√¢n ch·ªâ c·∫ßn c√≥ M·ªôt y·∫øu t·ªë ch√≠nh v·ªÅ t√¨nh d·ª•c v√† Hai tri·ªáu ch·ª©ng to√†n th√¢n (M·ªôt ch√≠nh, Hai ph·ª•) ƒë√£ n√™u trong ph·∫ßn tri·ªáu ch·ª©ng th√¨ ƒë∆∞·ª£c ch·∫©n ƒëo√°n l√† m√£n d·ª•c ·ªü nam gi·ªõi. | Score: 0.8969\n"
     ]
    }
   ],
   "source": [
    "from neo4j_vector import Neo4jVectorManager\n",
    "\n",
    "# Config k·∫øt n·ªëi Neo4j\n",
    "neo4j_config = {\n",
    "    \"url\": \"bolt://localhost:7687\",\n",
    "    \"username\": \"neo4j\",\n",
    "    \"password\": \"12345678\"\n",
    "}\n",
    "\n",
    "labels = [\"Disease\", \"Cause\", \"Symptom\", \"Treatment\", \"Prevention\", \"DiagnoseMethod\"]\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o\n",
    "manager = Neo4jVectorManager(neo4j_config)\n",
    "\n",
    "# 2. T·∫°o embeddings + indexes (ch·ªâ c·∫ßn ch·∫°y 1 l·∫ßn)\n",
    "manager.process_all_labels(labels)\n",
    "\n",
    "\n",
    "\n",
    "# 4. ƒê√≥ng k·∫øt n·ªëi\n",
    "manager.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0f088",
   "metadata": {},
   "source": [
    "## Find k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b981bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Disease] ·∫§u d√¢m l√† g√¨?\n",
      "·∫§u d√¢m l√† m·ªôt ch·ª©ng r·ªëi lo·∫°n t√¨nh d·ª•c g·ªìm nh·ªØng ham mu·ªën t√¨nh d·ª•c m·∫°nh m·∫Ω, li√™n t·ª•c m√† ƒë·ªëi t∆∞·ª£ng mu·ªën quan h·ªá l√† tr·∫ª em ch∆∞a ho·∫∑c m·ªõi d·∫≠y th√¨.\n",
      "C√°c h√†nh vi ·∫•u d√¢m bao g·ªìm: nh√¨n, vu·ªët ve, th·ªß d√¢m v√† √©p quan h·ªá t√¨nh d·ª•c v·ªõi tr·∫ª em. C√≥ m·ªôt s·ªë tr∆∞·ªùng h·ª£p ƒë·ªìng t√≠nh nam th√≠ch quan h·ªá v·ªõi c√°c c·∫≠u b√©, h·∫ßu h·∫øt ng∆∞·ªùi c√≥ xu h∆∞·ªõng ·∫•u d√¢m l√† nam gi·ªõi, nh∆∞ng c≈©ng c√≥ nh·ªØng tr∆∞·ªùng h·ª£p ng∆∞·ªùi b·ªánh l√† n·ªØ gi·ªõi.\n",
      "D∆∞·ªõi ·∫£nh h∆∞·ªüng c·ªßa gi·ªõi truy·ªÅn th√¥ng, ·∫•u d√¢m ƒë∆∞·ª£c hi·ªÉu l√† c√°c h√†nh ƒë·ªông l·∫°m d·ª•ng t√¨nh d·ª•c v·ªõi tr·∫ª em. Tuy nhi√™n, ƒë·ªãnh nghƒ©a n√†y ƒë√£ ph·∫£n √°nh sai t√¨nh h√¨nh chung c·ªßa nh·ªØng ng∆∞·ªùi m·∫Øc b·ªánh ·∫•u d√¢m, l√†m cho cƒÉn b·ªánh n√†y c√†ng kh√≥ nghi√™n c·ª©u v√† thu th·∫≠p s·ªë li·ªáu.\n",
      "·∫§u d√¢m l√† nh∆∞ th·∫ø n√†o?\n",
      "C·∫ßn kh·∫≥ng ƒë·ªãnh r·∫±ng ·∫•u d√¢m l√† b·ªánh, kh√¥ng ph·∫£i l√† t·ªôi. Kh√¥ng ph·∫£i b·∫•t k·ª≥ ai m·∫Øc b·ªánh ·∫•u d√¢m c≈©ng c√≥ h√†nh vi t√¨nh d·ª•c v·ªõi tr·∫ª em, c≈©ng nh∆∞ nh·ªØng ng∆∞·ªùi c√≥ h√†nh vi t√¨nh d·ª•c v·ªõi tr·∫ª em c≈©ng kh√¥ng ch·∫Øc ch·∫Øn l√† c√≥ b·ªánh ·∫•u d√¢m. (Score: 0.9137)\n"
     ]
    }
   ],
   "source": [
    "from neo4j_vector import Neo4jVectorManager\n",
    "\n",
    "# Config k·∫øt n·ªëi Neo4j\n",
    "neo4j_config = {\n",
    "    \"url\": \"bolt://localhost:7687\",\n",
    "    \"username\": \"neo4j\",\n",
    "    \"password\": \"12345678\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o\n",
    "manager = Neo4jVectorManager(neo4j_config)\n",
    "\n",
    "\n",
    "# 3. T√¨m ki·∫øm semantic similarity\n",
    "results = manager.similarity_search_git(\"Disease\", \"·∫§u d√¢m l√† g√¨ ?\", top_k=1)\n",
    "\n",
    "for label, text, score in results:\n",
    "    print(f\"[{label}] {text} (Score: {score:.4f})\")\n",
    "\n",
    "\n",
    "# 4. ƒê√≥ng k·∫øt n·ªëi\n",
    "manager.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0fe2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Label ph√°t hi·ªán: Cause\n",
      "[Cause] C√°c y·∫øu t·ªë ƒë∆∞·ª£c nghi√™n c·ª©u v√† gi·∫£ thuy·∫øt ƒë∆∞a ra nguy√™n nh√¢n g√¢y b·ªánh ·∫•u d√¢m nh∆∞: Ch·ªâ s·ªë IQ v√† tr√≠ nh·ªõ k√©m; √çt ch·∫•t tr·∫Øng trong n√£o b·ªô; √çt hormone testosterone; C√°c v·∫•n ƒë·ªÅ trong n√£o b·ªô. (Score: 0.8453)\n",
      "[Cause] Hi·ªán nay c√°c nh√† khoa h·ªçc v·∫´n ch∆∞a bi·∫øt ch√≠nh x√°c nguy√™n nh√¢n g√¢y ra ·∫•u d√¢m l√† g√¨. Do t√≠nh c√°ch v√† ho√†n c·∫£nh m·ªói ng∆∞·ªùi ƒë·ªÅu kh√°c nhau n√™n r·∫•t kh√≥ ƒë·ªÉ c√≥ th·ªÉ nghi√™n c·ª©u nguy√™n nh√¢n t·ª´ kh√≠a c·∫°nh t√¢m l√Ω. (Score: 0.8438)\n",
      "[Cause] C√≥ m·ªôt s·ªë chuy√™n gia cho r·∫±ng t√¨nh tr·∫°ng n√†y c√≥ li√™n quan ƒë·∫øn c√°c nh√¢n t·ªë t√¢m l√Ω x√£ h·ªôi ch·ª© kh√¥ng ph·∫£i c√°c nh√¢n t·ªë sinh h·ªçc, l·∫°i c√≥ m·ªôt s·ªë b√°c sƒ© cho r·∫±ng nh√¢n t·ªë t√≠nh c√°ch c√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn b·ªánh nh√¢n nh∆∞: c√°c v·∫•n ƒë·ªÅ v·ªÅ s·ª± g·∫Øn b√≥ ho·∫∑c ph·ª• thu·ªôc v√†o gia c·∫£nh b·∫•t th∆∞·ªùng, b·ªã qu·∫•y r·ªëi khi c√≤n nh·ªè c≈©ng c√≥ th·ªÉ l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n g√¢y ra ·∫•u d√¢m. (Score: 0.8305)\n",
      "[Cause] R·ªëi lo·∫°n t√¨nh d·ª•c. (Score: 0.8203)\n",
      "[Cause] C√°c b·ªánh l√¢y truy·ªÅn qua ƒë∆∞·ªùng t√¨nh d·ª•c; (Score: 0.8069)\n"
     ]
    }
   ],
   "source": [
    "from neo4j_vector import Neo4jVectorManager\n",
    "\n",
    "# Config k·∫øt n·ªëi Neo4j\n",
    "neo4j_config = {\n",
    "    \"url\": \"bolt://localhost:7687\",\n",
    "    \"username\": \"neo4j\",\n",
    "    \"password\": \"12345678\"\n",
    "}\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o\n",
    "manager = Neo4jVectorManager(neo4j_config)\n",
    "\n",
    "query = \"Nguy√™n nh√¢n ·∫•u d√¢m ?\"\n",
    "\n",
    "label = manager.detect_label_from_query_git(query)\n",
    "print(f\"üîé Label ph√°t hi·ªán: {label}\")\n",
    "\n",
    "results = manager.similarity_search_git(label=label, query_text=query)\n",
    "\n",
    "for lbl, text, score in results:\n",
    "    print(f\"[{lbl}] {text} (Score: {score:.4f})\")\n",
    "\n",
    "manager.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a901d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Master\\Data & Structure\\Paper_KG\\Doan\\graphrag-chatbot-medical\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from neo4j_vector import Neo4jVectorManager\n",
    "\n",
    "\n",
    "# C·∫•u h√¨nh k·∫øt n·ªëi\n",
    "neo4j_config = {\n",
    "    \"url\": \"bolt://localhost:7687\",\n",
    "    \"username\": \"neo4j\",\n",
    "    \"password\": \"12345678\"\n",
    "}\n",
    "\n",
    "def search_similar_nodes(query):\n",
    "    manager = Neo4jVectorManager(neo4j_config)\n",
    "    try:\n",
    "        label = manager.detect_label_from_query_git(query)\n",
    "        results = manager.similarity_search_git(label=label, query_text=query)\n",
    "\n",
    "        output_lines = [f\"üîé ƒê√£ ph√°t hi·ªán label: {label}\\n\"]\n",
    "        for lbl, text, score in results:\n",
    "            output_lines.append(f\"üß© {text}\")\n",
    "        return \"\\n\\n\".join(output_lines)\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå L·ªói: {str(e)}\"\n",
    "    finally:\n",
    "        manager.close()\n",
    "\n",
    "# Giao di·ªán Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=search_similar_nodes,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Nh·∫≠p c√¢u h·ªèi nh∆∞: 'AIDS l√† g√¨?'\"),\n",
    "    outputs=gr.Textbox(label=\"K·∫øt qu·∫£ t∆∞∆°ng t·ª±\"),\n",
    "    title=\"üß† Semantic Search (Neo4j + SimCSE)\",\n",
    "    description=\"T√¨m ki·∫øm c√°c node y h·ªçc t∆∞∆°ng t·ª± trong ƒë·ªì th·ªã Neo4j theo vector embedding (PhoBERT + cosine).\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d329ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Master\\Data & Structure\\Paper_KG\\Doan\\graphrag-chatbot-medical\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from neo4j_vector import Neo4jVectorManager\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# C·∫•u h√¨nh k·∫øt n·ªëi Neo4j\n",
    "neo4j_config = {\n",
    "    \"url\": \"bolt://localhost:7687\",\n",
    "    \"username\": \"neo4j\",\n",
    "    \"password\": \"12345678\"\n",
    "}\n",
    "\n",
    "# Prompt t√≥m t·∫Øt k·∫øt qu·∫£ b·∫±ng LLM\n",
    "template = \"\"\"\n",
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω y t·∫ø th√¥ng minh. D∆∞·ªõi ƒë√¢y l√† c√°c ƒëo·∫°n th√¥ng tin g·∫ßn gi·ªëng v·ªõi c√¢u h·ªèi:\n",
    "\n",
    "C√¢u h·ªèi: {question}\n",
    "\n",
    "C√°c ƒëo·∫°n li√™n quan:\n",
    "{contexts}\n",
    "\n",
    "H√£y t√≥m t·∫Øt l·∫°i m·ªôt c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒë√∫ng chuy√™n m√¥n.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm = Ollama(model=\"phi\")  # B·∫°n c√≥ th·ªÉ ƒë·ªïi th√†nh \"gemma\", \"mistral\", ho·∫∑c OpenAI\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# H√†m x·ª≠ l√Ω t√¨m ki·∫øm + t√≥m t·∫Øt\n",
    "def search_and_summarize(query):\n",
    "    manager = Neo4jVectorManager(neo4j_config)\n",
    "    try:\n",
    "        label = manager.detect_label_from_query_git(query)\n",
    "        results = manager.similarity_search_git(label=label, query_text=query, top_k=5)\n",
    "\n",
    "        if not results:\n",
    "            return f\"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho label {label}.\"\n",
    "\n",
    "        # Format cho hi·ªÉn th·ªã\n",
    "        display_output = f\"üîé ƒê√£ ph√°t hi·ªán label: {label}\\n\\n\"\n",
    "        for i, (_, name, _) in enumerate(results, 1):\n",
    "            display_output += f\"üß© {i}. {name}\\n\"\n",
    "\n",
    "        # T√≥m t·∫Øt b·∫±ng LLM\n",
    "        contexts = \"\\n\".join(f\"- {name}\" for _, name, _ in results)\n",
    "        answer = llm_chain.run({\"question\": query, \"contexts\": contexts})\n",
    "\n",
    "        return f\"{display_output}\\n\\nüß† **C√¢u tr·∫£ l·ªùi b·ªüi LLM:**\\n{answer}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå L·ªói: {str(e)}\"\n",
    "    finally:\n",
    "        manager.close()\n",
    "\n",
    "# Giao di·ªán Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=search_and_summarize,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Nh·∫≠p c√¢u h·ªèi nh∆∞: 'Nguy√™n nh√¢n b·ªánh ti·ªÉu ƒë∆∞·ªùng?'\"),\n",
    "    outputs=gr.Textbox(label=\"K·∫øt qu·∫£ + Tr·∫£ l·ªùi b·ªüi LLM\", lines=10),\n",
    "    title=\"üß† Semantic QA (Neo4j + SimCSE + LLM)\",\n",
    "    description=\"T√¨m ki·∫øm tri th·ª©c y h·ªçc t·ª´ Neo4j v√† tr·∫£ l·ªùi t·ª± nhi√™n b·∫±ng LLM (phi/mistral/gemma).\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "\n",
    "# G·ªôp nhi·ªÅu retrievers\n",
    "retrievers = [\n",
    "    store.as_retriever(search_kwargs={\"k\": 10}) for store in vectorstores.values()\n",
    "]\n",
    "\n",
    "# G·ªôp th√†nh 1 retriever duy nh·∫•t\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retrievers,\n",
    "    weights=[1] * len(retrievers)  # m·ªói vectorstore tr·ªçng s·ªë b·∫±ng nhau\n",
    ")\n",
    "\n",
    "# T·∫°o chain RAG\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = Ollama(model=\"phi\"),  # ho·∫∑c Huggingface\n",
    "    retriever=ensemble_retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# T·∫°o retrievers v·ªõi search_kwargs ri√™ng\n",
    "retrievers = [\n",
    "    vectorstores[\"Disease\"].as_retriever(search_kwargs={\"k\": 3}),\n",
    "    vectorstores[\"Cause\"].as_retriever(search_kwargs={\"k\": 3}),\n",
    "    vectorstores[\"Symptom\"].as_retriever(search_kwargs={\"k\": 2}),\n",
    "    vectorstores[\"Treatment\"].as_retriever(search_kwargs={\"k\": 2}),\n",
    "    vectorstores[\"Prevention\"].as_retriever(search_kwargs={\"k\": 1}),\n",
    "    vectorstores[\"DiagnoseMethod\"].as_retriever(search_kwargs={\"k\": 1}),\n",
    "]\n",
    "\n",
    "# Tr·ªçng s·ªë ∆∞u ti√™n (Disease & Cause n·∫∑ng h∆°n)\n",
    "weights = [3, 3, 2, 2, 1, 1]\n",
    "\n",
    "# G·ªôp retrievers\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retrievers,\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "# T·∫°o QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=Ollama(model=\"phi\"),\n",
    "    retriever=ensemble_retriever,\n",
    "    chain_type=\"stuff\"  # C√≥ th·ªÉ thay b·∫±ng map_reduce, refine n·∫øu c·∫ßn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea999474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"dangvantuan/vietnamese-embedding\" # ho·∫∑c \"cpu\"\n",
    ")\n",
    "\n",
    "vector = embeddings.embed_query(\"Test embedding\")\n",
    "print(vector[:10])  # In th·ª≠ 10 ph·∫ßn t·ª≠ ƒë·∫ßu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=embeddings,\n",
    "    search_type=\"hybrid\",  # or \"similarity\"\n",
    "    node_label=\"Disease\",  # üëà l·∫•y t·∫•t c·∫£\n",
    "    text_node_properties=[\"name\", \"overview\"],  # ƒë·∫£m b·∫£o c√°c node c√≥ tr∆∞·ªùng name\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b42912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # v√≠ d·ª•: Ollama(model=\"phi\")\n",
    "    retriever=vector_index.as_retriever(search_kwargs={\"k\": 5})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed31020",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Nguy√™n nh√¢n c·ªßa AIDS l√† g√¨?\"\n",
    "response = qa_chain.run(query)\n",
    "print(\"ü§ñ Tr·∫£ l·ªùi:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce089f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def ask_graph_rag(question):\n",
    "    return qa_chain.run(question)\n",
    "\n",
    "gr.Interface(\n",
    "    fn=ask_graph_rag,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"GraphRAG Medical Chatbot üß†\",\n",
    "    description=\"Truy v·∫•n tri th·ª©c t·ª´ ƒë·ªì th·ªã y t·∫ø \",\n",
    ").launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
