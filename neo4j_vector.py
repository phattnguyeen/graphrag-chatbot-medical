import os
import torch
from neo4j import GraphDatabase
from transformers import AutoTokenizer, AutoModel
from underthesea import word_tokenize

# ==== 1. H√†m t·∫°o embedding ====

def hf_text_embedding(text, tokenizer, model):
    """Sinh embedding t·ª´ text b·∫±ng HuggingFace model"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state[:, 0, :]
    return embeddings.squeeze().cpu().numpy().tolist()

# ==== 2. Class qu·∫£n l√Ω Vector Index ====

class Neo4jVectorManager:
    def __init__(self, neo4j_config, model_name="VoVanPhuc/sup-SimCSE-VietNamese-phobert-base", embedding_dim=768):
        """Kh·ªüi t·∫°o k·∫øt n·ªëi Neo4j v√† load model"""
        self.driver = GraphDatabase.driver(
            neo4j_config["url"],
            auth=(neo4j_config["username"], neo4j_config["password"])
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.embedding_dim = embedding_dim

    def generate_embeddings(self, label, text_field="name"):
        """Sinh embedding cho t·∫•t c·∫£ node theo label"""
        with self.driver.session() as session:
            print(f"üîµ ƒêang t·∫°o embedding cho {label}...")
            results = session.run(f"""
                MATCH (n:{label})
                WHERE n.{text_field} IS NOT NULL
                RETURN id(n) AS id, n.{text_field} AS text
            """)
            for record in results:
                node_id = record["id"]
                text = record["text"]
                if text:
                    segmented = word_tokenize(text, format="text")
                    embedding = hf_text_embedding(segmented, self.tokenizer, self.model)
                    session.run("""
                        MATCH (n) WHERE id(n) = $id
                        SET n.embedding = $embedding
                    """, {"id": node_id, "embedding": embedding})

    def create_vector_index(self, label):
        """T·∫°o VECTOR INDEX cho label"""
        index_name = f"index_{label.lower()}"
        print(f"üõ†Ô∏è  ƒêang t·∫°o vector index cho {label} ({index_name})...")
        with self.driver.session() as session:
            session.run(f"""
                CALL db.index.vector.createNodeIndex(
                    '{index_name}',
                    '{label}',
                    'embedding',
                    {self.embedding_dim},
                    'cosine'
                )
            """)
        print(f"‚úÖ ƒê√£ t·∫°o vector index {index_name}!")

    def process_all_labels(self, labels):
        """T·∫°o embedding v√† index cho nhi·ªÅu label"""
        for label in labels:
            try:
                self.generate_embeddings(label)
                self.create_vector_index(label)
            except Exception as e:
                print(f"‚ùå L·ªói khi x·ª≠ l√Ω label {label}: {str(e)}")

    def similarity_search_git(self, label, query_text, top_k=5):
        """T√¨m ki·∫øm similarity trong vector index"""
        if label.lower() == "disease":
            top_k = 1
        segmented = word_tokenize(query_text, format="text")
        query_embedding = hf_text_embedding(segmented, self.tokenizer, self.model)
        index_name = f"index_{label.lower()}"

        with self.driver.session() as session:
            results = session.run(f"""
                CALL db.index.vector.queryNodes(
                    $index_name,
                    $top_k,
                    $embedding
                )
                YIELD node, score
                RETURN 
                labels(node)[0] AS label,
                CASE 
                    WHEN labels(node)[0] = 'Disease' THEN coalesce(node.overview, node.name)
                    ELSE node.name
                END AS text,score
                ORDER BY score DESC
            """, {
                "index_name": index_name,
                "top_k": top_k,
                "embedding": query_embedding
            })
            return [(record["label"], record["text"], record["score"]) for record in results]

    def search_across_labels(self, query_text, labels, top_k=3):
        """T√¨m ki·∫øm semantic tr√™n nhi·ªÅu labels"""
        all_results = []
        for label in labels:
            try:
                res = self.similarity_search_git(label, query_text, top_k=top_k)
                all_results.extend(res)
            except Exception as e:
                print(f"‚ùó L·ªói khi search label {label}: {str(e)}")
        all_results.sort(key=lambda x: x[2], reverse=True)  # Sort theo score
        return all_results

    def detect_label_from_query_git(self, query_text):
        """T·ª± ƒë·ªông nh·∫≠n di·ªán label t·ª´ c√¢u h·ªèi"""
        query = query_text.lower()
        if any(k in query for k in ["ph√≤ng", "ng·ª´a", "tr√°nh"]):
            return "Prevention"
        elif any(k in query for k in ["tri·ªáu ch·ª©ng", "d·∫•u hi·ªáu", "bi·ªÉu hi·ªán"]):
            return "Symptom"
        elif any(k in query for k in ["nguy√™n nh√¢n", "t·∫°i sao", "v√¨ sao"]):
            return "Cause"
        elif any(k in query for k in ["ch·∫©n ƒëo√°n", "x√©t nghi·ªám"]):
            return "DiagnoseMethod"
        elif any(k in query for k in ["ƒëi·ªÅu tr·ªã", "thu·ªëc", "c√°ch ch·ªØa", "ph√°c ƒë·ªì"]):
            return "Treatment"
        elif any(k in query for k in ["b·ªánh", "l√† g√¨", "th√¥ng tin", "ƒë·ªãnh nghƒ©a"]):
            return "Disease"
        else:
            return "Disease"  # fallback

    def close(self):
        """ƒê√≥ng k·∫øt n·ªëi Neo4j"""
        self.driver.close()
